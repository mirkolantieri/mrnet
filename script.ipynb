{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#%matplotlib inline\n",
    "import random\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from IPython.display import HTML\n",
    "from skimage.io import imsave\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# Root directory for dataset\n",
    "dataroot = \"./output/\"\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Class\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Discriminator class\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Resize(image_size),\n",
    "                                transforms.CenterCrop(image_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=workers)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    " # Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)\n",
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)\n",
    "\n",
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "# For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "            ############################\n",
    "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            ###########################\n",
    "            ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "            # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "############################\n",
    "            # (2) Update G network: maximize log(D(G(z)))\n",
    "            ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "# Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                    % (epoch, num_epochs, i, len(dataloader),\n",
    "                        errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "            # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "            # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "if not os.path.exists('./gans/'):\n",
    "    os.mkdir('./gans/')\n",
    "\n",
    "for i in range(len(img_list)):\n",
    "    image0 = img_list[i]\n",
    "    save_image(image0, f'./gans/gan_{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import utils as ut\n",
    "from loader import MRDataset\n",
    "from model import AlexNet\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_predictions(task, plane, path_to_models, train=True):\n",
    "    \"\"\" \n",
    "    `extract_predictions`: the method extracts the prediction from the pretrained models\n",
    "\n",
    "    args:\n",
    "        task: the tear to be analized (acl, meniscus, abnormal)\n",
    "        plane: the plane where the tear occured (for example: axial, coronal, sagittal)\n",
    "        path_to_models: the path where are stored the trained models\n",
    "        trains=True: boolean to indicate if the loader needs to be from the training set or the validation\n",
    "\n",
    "    \"\"\"\n",
    "    assert task in ['acl', 'meniscus', 'abnormal']\n",
    "    assert plane in ['axial', 'coronal', 'sagittal']\n",
    "    \n",
    "    # Initialize the models and filter by the tear\n",
    "    models = os.listdir(path_to_models)\n",
    "    model_name = list(filter(lambda name: task in name and plane in name, models))[0]\n",
    "    model_path = f'{path_to_models}/{model_name}'\n",
    "\n",
    "    # Select the gpu or the cpu for the tensor compilation\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else: \n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    model = AlexNet()\n",
    "\n",
    "    # Load the model\n",
    "    mrnet = torch.load(model_path)\n",
    "    model.load_state_dict(mrnet)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Create the traning set and send to the loader\n",
    "    dataset = MRDataset('./data/', task, plane, train=train)\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2, drop_last=False)\n",
    "\n",
    "    \n",
    "    # Create the array list to store the predictions and labels from the compiled model\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    # While compiling without gradient, add each single item from the labels and prediction\n",
    "    # to the above defined array lists \n",
    "    # and then return it \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label, _ in tqdm.tqdm(loader):\n",
    "            image = image.to(device)\n",
    "            logit = model(image)\n",
    "            prediction = torch.sigmoid(logit)\n",
    "            predictions.append(prediction[0].item())\n",
    "            labels.append(label[0].item())\n",
    "    \n",
    "    return np.argmax(predictions), np.argmax(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_results_val = {}\n",
    "\n",
    "for task in ['acl', 'meniscus', 'abnormal']:\n",
    "    results = {}\n",
    "\n",
    "    # Train a logistic regressor model\n",
    "    for plane in ['axial', 'coronal', 'sagittal']:\n",
    "        prediction = extract_predictions(task, plane, './experiments/exp_opt_acc/models/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regressor for the validation test\n",
    "results_val = {}\n",
    "\n",
    "for plane in ['axial', 'coronal', 'sagittal']:\n",
    "    predictions, labels = extract_predictions(task, plane, './experiments/exp_opt_acc/models/', train=True)\n",
    "    results_val['labels'] = labels\n",
    "    results_val[plane] = predictions\n",
    "\n",
    "X_val = np.zeros((len(predictions), 3))\n",
    "X_val[:, 0] = results_val['axial']\n",
    "X_val[:, 1] = results_val['coronal']\n",
    "X_val[:, 2] = results_val['sagittal']\n",
    "\n",
    "y_val = np.array(labels)\n",
    "\n",
    "y_pred = logreg.predict_proba(X_val)[:, 1]\n",
    "y_class_preds = (y_pred > 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex = [ 280,97,77,394,259,115,314,123,100,279,150,30,309,381,231,94,146,230,325,339,258,137,193,298,207 ]\n",
    "complex = pd.DataFrame(complex)\n",
    "\n",
    "abnormal_complex = pd.read_csv('./experiments/exp_auc/results/complex-abnormal-prediction.csv')\n",
    "abnormal_complex_label = pd.read_csv('./experiments/exp_auc/results/complex-abnormal-label.csv')\n",
    "\n",
    "acl_complex = pd.read_csv('./experiments/exp_auc/results/complex-acl-prediction.csv')\n",
    "acl_complex_label = pd.read_csv('./experiments/exp_auc/results/complex-acl-label.csv')\n",
    "\n",
    "meniscus_complex = pd.read_csv('./experiments/exp_auc/results/complex-meniscus-prediction.csv')\n",
    "meniscus_complex_label = pd.read_csv('./experiments/exp_auc/results/complex-meniscus-label.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_complex = abnormal_complex.rename(columns={'Unnamed: 0' : \"Case\", \"0\" : \"Prediction\"})\n",
    "abnormal_complex = abnormal_complex.set_index(\"Case\")\n",
    "\n",
    "acl_complex = acl_complex.rename(columns={'Unnamed: 0' : \"Case\", \"0\" : \"Prediction\"})\n",
    "acl_complex = acl_complex.set_index(\"Case\")\n",
    "\n",
    "meniscus_complex = meniscus_complex.rename(columns={'Unnamed: 0' : \"Case\", \"0\" : \"Prediction\"})\n",
    "meniscus_complex = meniscus_complex.set_index(\"Case\")\n",
    "\n",
    "abnormal_complex_label = abnormal_complex_label.rename(columns={'Unnamed: 0' : \"Case\", \"0\" : \"Prediction\"})\n",
    "abnormal_complex_label = abnormal_complex_label.set_index(\"Case\")\n",
    "\n",
    "acl_complex_label = acl_complex_label.rename(columns={'Unnamed: 0' : \"Case\", \"0\" : \"Prediction\"})\n",
    "acl_complex_label = acl_complex_label.set_index(\"Case\")\n",
    "\n",
    "meniscus_complex_label = meniscus_complex_label.rename(columns={'Unnamed: 0' : \"Case\", \"0\" : \"Prediction\"})\n",
    "meniscus_complex_label = meniscus_complex_label.set_index(\"Case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex = complex.rename(columns={0: \"Case\"})\n",
    "complex = complex.set_index(\"Case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_complex[\"True Label\"] = abnormal_complex_label[\"Prediction\"]\n",
    "acl_complex[\"True Label\"] = acl_complex_label[\"Prediction\"]\n",
    "meniscus_complex[\"True Label\"] = meniscus_complex_label[\"Prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ab = abnormal_complex[\"Prediction\"].to_numpy()\n",
    "y_val_ab = abnormal_complex[\"True Label\"].to_numpy()\n",
    "\n",
    "y_pred_acl = acl_complex[\"Prediction\"].to_numpy()\n",
    "y_val_acl = acl_complex[\"True Label\"].to_numpy()\n",
    "\n",
    "y_pred_men = meniscus_complex[\"Prediction\"].to_numpy()\n",
    "y_val_men = meniscus_complex[\"True Label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc1 = metrics.roc_auc_score(y_val_ab , y_pred_ab)\n",
    "auc2 = metrics.roc_auc_score(y_val_acl , y_pred_acl)\n",
    "auc3 = metrics.roc_auc_score(y_val_men , y_pred_men)\n",
    "plt.figure(0).clf()\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_val_ab, y_pred_ab)\n",
    "plt.plot(fpr,tpr,label=f\"Task abnormal, auc=\"+str(auc1))\n",
    "plt.title(f'Complex case - ROC/AUROC graph (Model AUC)')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_val_acl, y_pred_acl)\n",
    "plt.plot(fpr,tpr,label=f\"Task acl, auc=\"+str(auc2))\n",
    "\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_val_men, y_pred_men)\n",
    "plt.plot(fpr,tpr,label=f\"Task meniscus, auc=\"+str(auc3))\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.savefig(f'./complex-roc-auc.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_complex['True Label'] = abnormal_complex_label['Prediction']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_complex.loc[abnormal_complex['Prediction'] != abnormal_complex['True Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_complex = abnormal_complex.loc[abnormal_complex['Case'] == pd.DataFrame(complex)]\n",
    "abnormal_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.to_csv('./pred_auc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl_acc = pd.read_csv(f'./experiments/exp_opt_acc/results/complex-acl-prediction.csv')\n",
    "abnormal_acc = pd.read_csv(f'./experiments/exp_opt_acc/results/complex-abnormal-prediction.csv')\n",
    "meniscus_acc = pd.read_csv(f'./experiments/exp_opt_acc/results/complex-meniscus-prediction.csv')\n",
    "\n",
    "acl_wu = pd.read_csv(f'./experiments/exp_opt_wu/results/complex-acl-prediction.csv')\n",
    "abnormal_wu = pd.read_csv(f'./experiments/exp_opt_wu/results/complex-abnormal-prediction.csv')\n",
    "meniscus_wu = pd.read_csv(f'./experiments/exp_opt_wu/results/complex-meniscus-prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl_acc = acl_acc.rename(columns={\"Unnamed: 0\": \"Case\", \"0\": \"Score\"})\n",
    "abnormal_acc = abnormal_acc.rename(columns={\"Unnamed: 0\": \"Case\", \"0\": \"Score\"})\n",
    "meniscus_acc = meniscus_acc.rename(columns={\"Unnamed: 0\": \"Case\", \"0\": \"Score\"})\n",
    "\n",
    "acl_wu = acl_wu.rename(columns={\"Unnamed: 0\": \"Case\", \"0\": \"Score\"})\n",
    "abnormal_wu = abnormal_wu.rename(columns={\"Unnamed: 0\": \"Case\", \"0\": \"Score\"})\n",
    "meniscus_wu = meniscus_wu.rename(columns={\"Unnamed: 0\": \"Case\", \"0\": \"Score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl_acc[\"Prediction\"] = acl_acc['Score'] == 1\n",
    "abnormal_acc[\"Prediction\"] = abnormal_acc['Score'] == 1\n",
    "meniscus_acc[\"Prediction\"] = meniscus_acc['Score'] == 1\n",
    "\n",
    "\n",
    "acl_wu[\"Prediction\"] = acl_wu['Score'] == 1\n",
    "abnormal_wu[\"Prediction\"] = abnormal_wu['Score'] == 1\n",
    "meniscus_wu[\"Prediction\"] = meniscus_wu['Score'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl_acc = acl_acc.set_index('Case')\n",
    "abnormal_acc = abnormal_acc.set_index('Case')\n",
    "meniscus_acc = meniscus_acc.set_index('Case')\n",
    "\n",
    "acl_wu = acl_wu.set_index('Case')\n",
    "abnormal_wu = abnormal_wu.set_index('Case')\n",
    "meniscus_wu = meniscus_wu.set_index('Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acl Accuracy')\n",
    "print(acl_acc.loc[acl_acc['Score'] != acl_wu['Score']])\n",
    "print('-'*30)\n",
    "print('\\nAcl WU')\n",
    "print(acl_wu.loc[acl_acc['Score'] != acl_wu['Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Abnormal Accuracy')\n",
    "print(abnormal_acc.loc[abnormal_acc['Score'] != abnormal_wu['Score']])\n",
    "print('-'*30)\n",
    "print('\\nAbnormal WU')\n",
    "print(abnormal_wu.loc[abnormal_acc['Score'] != abnormal_wu['Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Meniscus Accuracy')\n",
    "print(meniscus_acc.loc[meniscus_acc['Score'] != meniscus_wu['Score']])\n",
    "print('-'*30)\n",
    "print('\\nMeniscus WU')\n",
    "print(meniscus_wu.loc[meniscus_acc['Score'] != meniscus_wu['Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl_acc.to_csv(f'./experiments/exp_opt_acc/results/complex-acl-prediction.csv')\n",
    "abnormal_acc.to_csv(f'./experiments/exp_opt_acc/results/complex-abnormal-prediction.csv')\n",
    "meniscus_acc.to_csv(f'./experiments/exp_opt_acc/results/complex-meniscus-prediction.csv')\n",
    "\n",
    "acl_wu.to_csv(f'./experiments/exp_opt_wu/results/complex-acl-prediction.csv')\n",
    "abnormal_wu.to_csv(f'./experiments/exp_opt_wu/results/complex-abnormal-prediction.csv')\n",
    "meniscus_wu.to_csv(f'./experiments/exp_opt_wu/results/complex-meniscus-prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0).clf()\n",
    "\n",
    "pred = np.random.rand(1000)\n",
    "label = np.random.randint(2, size=1000)\n",
    "fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
    "auc = metrics.roc_auc_score(label, pred)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "\n",
    "pred = np.random.rand(1000)\n",
    "label = np.random.randint(2, size=1000)\n",
    "fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
    "auc = metrics.roc_auc_score(label, pred)\n",
    "plt.plot(fpr,tpr,label=\"data 2, auc=\"+str(auc))\n",
    "\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "axial = './data/train/axial/'\n",
    "count = 0\n",
    "\n",
    "for image in os.listdir(axial):\n",
    "    img = os.path.join(axial, image)\n",
    "    img = np.load(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        arr = Image.fromarray(img[i, :, :])\n",
    "        arr.save(f'./images/axial/{image}-{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coronal = './data/train/coronal/'\n",
    "count = 0\n",
    "\n",
    "for image in os.listdir(coronal):\n",
    "    img = os.path.join(coronal, image)\n",
    "    img = np.load(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        arr = Image.fromarray(img[i, :, :])\n",
    "        arr.save(f'./images/coronal/{image}-{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sagittal = './data/train/sagittal/'\n",
    "count = 0\n",
    "\n",
    "for image in os.listdir(sagittal):\n",
    "    img = os.path.join(sagittal, image)\n",
    "    img = np.load(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        arr = Image.fromarray(img[i, :, :])\n",
    "        arr.save(f'./images/sagittal/{image}-{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "from models.res_similar import SimilarRes18\n",
    "from PIL import Image\n",
    "\n",
    "ut.rescale_image('./selected/', './rescaled')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "img2vec = SimilarRes18()\n",
    "\n",
    "allVectors = {}\n",
    "print(\"Converting images to feature vectors:\")\n",
    "for image in tqdm(os.listdir(\"./rescaled/\")):\n",
    "    I = Image.open(os.path.join(\"./rescaled/\", image))\n",
    "    vec = img2vec.getVec(I)\n",
    "    allVectors[image] = vec\n",
    "    I.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarityMatrix = ut.get_similarity_matrix(allVectors)\n",
    "similarNames, similarValues = ut.top_entries(10, similarityMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = []\n",
    "\n",
    "for i in os.listdir('./selected/'):\n",
    "    img.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.sort()\n",
    "for i in img:\n",
    "    ut.plot_similar_images('./selected/', i, 10, 1, similarNames, similarValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/train-abnormal.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1dd53c9a3d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/train-abnormal.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/train-abnormal.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "label = pd.read_csv('./data/train-abnormal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0000  1\n",
       "12     13  1\n",
       "15     16  1\n",
       "32     33  1\n",
       "75     76  1\n",
       "82     83  1\n",
       "98     99  0\n",
       "100   101  1\n",
       "114   115  1\n",
       "175   176  1\n",
       "178   179  1\n",
       "189   190  1\n",
       "208   209  1\n",
       "218   219  1\n",
       "226   227  0\n",
       "237   238  0\n",
       "243   244  0\n",
       "244   245  0\n",
       "260   261  1\n",
       "264   265  1\n",
       "270   271  1\n",
       "281   282  1\n",
       "285   286  1\n",
       "302   303  1\n",
       "328   329  1\n",
       "404   405  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [101,  16, 179, 265,  33,  83, 271, 238, 286, 329,\n",
    "        99, 405, 209, 282, 190, 219, 227, 115,   13, 303,\n",
    "        261, 245, 176, 244,  76, 405]\n",
    "label[label['0000'].isin(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = pd.read_csv('./images/sim_matrix.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = im1.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case325coronal.jpg</th>\n",
       "      <th>case122coronal.jpg</th>\n",
       "      <th>case326sagittal.jpg</th>\n",
       "      <th>case231sagittal.jpg</th>\n",
       "      <th>case30coronal.jpg</th>\n",
       "      <th>case297axial.jpg</th>\n",
       "      <th>case219sagittal.jpg</th>\n",
       "      <th>case286axial.jpg</th>\n",
       "      <th>case314axial.jpg</th>\n",
       "      <th>case297coronal.jpg</th>\n",
       "      <th>...</th>\n",
       "      <th>case13axial.jpg</th>\n",
       "      <th>case300sagittal.jpg</th>\n",
       "      <th>case285coronal.jpg</th>\n",
       "      <th>case188axial.jpg</th>\n",
       "      <th>case259axial.jpg</th>\n",
       "      <th>case277sagittal.jpg</th>\n",
       "      <th>case197coronal.jpg</th>\n",
       "      <th>case381sagittal.jpg</th>\n",
       "      <th>case303sagittal.jpg</th>\n",
       "      <th>case107coronal.jpg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>case325coronal.jpg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832942</td>\n",
       "      <td>0.735341</td>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.865807</td>\n",
       "      <td>0.638015</td>\n",
       "      <td>0.779249</td>\n",
       "      <td>0.625735</td>\n",
       "      <td>0.605672</td>\n",
       "      <td>0.870615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652710</td>\n",
       "      <td>0.690363</td>\n",
       "      <td>0.862223</td>\n",
       "      <td>0.623290</td>\n",
       "      <td>0.638169</td>\n",
       "      <td>0.782505</td>\n",
       "      <td>0.804853</td>\n",
       "      <td>0.790026</td>\n",
       "      <td>0.766346</td>\n",
       "      <td>0.832891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case122coronal.jpg</th>\n",
       "      <td>0.832942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733826</td>\n",
       "      <td>0.750069</td>\n",
       "      <td>0.852577</td>\n",
       "      <td>0.560129</td>\n",
       "      <td>0.721328</td>\n",
       "      <td>0.651814</td>\n",
       "      <td>0.523295</td>\n",
       "      <td>0.851646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634690</td>\n",
       "      <td>0.693746</td>\n",
       "      <td>0.798509</td>\n",
       "      <td>0.538192</td>\n",
       "      <td>0.558052</td>\n",
       "      <td>0.794565</td>\n",
       "      <td>0.799801</td>\n",
       "      <td>0.808801</td>\n",
       "      <td>0.710590</td>\n",
       "      <td>0.908051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case326sagittal.jpg</th>\n",
       "      <td>0.735341</td>\n",
       "      <td>0.733826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799325</td>\n",
       "      <td>0.700186</td>\n",
       "      <td>0.638328</td>\n",
       "      <td>0.827238</td>\n",
       "      <td>0.677034</td>\n",
       "      <td>0.610330</td>\n",
       "      <td>0.741205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676747</td>\n",
       "      <td>0.720970</td>\n",
       "      <td>0.718583</td>\n",
       "      <td>0.626541</td>\n",
       "      <td>0.657490</td>\n",
       "      <td>0.760559</td>\n",
       "      <td>0.674147</td>\n",
       "      <td>0.856096</td>\n",
       "      <td>0.797673</td>\n",
       "      <td>0.739138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case231sagittal.jpg</th>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.750069</td>\n",
       "      <td>0.799325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822330</td>\n",
       "      <td>0.642854</td>\n",
       "      <td>0.825810</td>\n",
       "      <td>0.725837</td>\n",
       "      <td>0.592414</td>\n",
       "      <td>0.836343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700607</td>\n",
       "      <td>0.740973</td>\n",
       "      <td>0.843259</td>\n",
       "      <td>0.618296</td>\n",
       "      <td>0.645350</td>\n",
       "      <td>0.830331</td>\n",
       "      <td>0.778042</td>\n",
       "      <td>0.823692</td>\n",
       "      <td>0.856342</td>\n",
       "      <td>0.763233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case30coronal.jpg</th>\n",
       "      <td>0.865807</td>\n",
       "      <td>0.852577</td>\n",
       "      <td>0.700186</td>\n",
       "      <td>0.822330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.527503</td>\n",
       "      <td>0.698878</td>\n",
       "      <td>0.632859</td>\n",
       "      <td>0.512146</td>\n",
       "      <td>0.869455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598190</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.906558</td>\n",
       "      <td>0.511522</td>\n",
       "      <td>0.549753</td>\n",
       "      <td>0.794605</td>\n",
       "      <td>0.891447</td>\n",
       "      <td>0.752369</td>\n",
       "      <td>0.762811</td>\n",
       "      <td>0.866054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case277sagittal.jpg</th>\n",
       "      <td>0.782505</td>\n",
       "      <td>0.794565</td>\n",
       "      <td>0.760559</td>\n",
       "      <td>0.830331</td>\n",
       "      <td>0.794605</td>\n",
       "      <td>0.663027</td>\n",
       "      <td>0.797273</td>\n",
       "      <td>0.703301</td>\n",
       "      <td>0.599241</td>\n",
       "      <td>0.795753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698124</td>\n",
       "      <td>0.801582</td>\n",
       "      <td>0.790188</td>\n",
       "      <td>0.648495</td>\n",
       "      <td>0.658357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795315</td>\n",
       "      <td>0.801778</td>\n",
       "      <td>0.872365</td>\n",
       "      <td>0.767610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case197coronal.jpg</th>\n",
       "      <td>0.804853</td>\n",
       "      <td>0.799801</td>\n",
       "      <td>0.674147</td>\n",
       "      <td>0.778042</td>\n",
       "      <td>0.891447</td>\n",
       "      <td>0.553108</td>\n",
       "      <td>0.667857</td>\n",
       "      <td>0.628135</td>\n",
       "      <td>0.537501</td>\n",
       "      <td>0.783069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612077</td>\n",
       "      <td>0.720362</td>\n",
       "      <td>0.887545</td>\n",
       "      <td>0.541602</td>\n",
       "      <td>0.582140</td>\n",
       "      <td>0.795315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686129</td>\n",
       "      <td>0.750331</td>\n",
       "      <td>0.834596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case381sagittal.jpg</th>\n",
       "      <td>0.790026</td>\n",
       "      <td>0.808801</td>\n",
       "      <td>0.856096</td>\n",
       "      <td>0.823692</td>\n",
       "      <td>0.752369</td>\n",
       "      <td>0.660473</td>\n",
       "      <td>0.860385</td>\n",
       "      <td>0.763673</td>\n",
       "      <td>0.620356</td>\n",
       "      <td>0.801669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730586</td>\n",
       "      <td>0.702392</td>\n",
       "      <td>0.731659</td>\n",
       "      <td>0.644453</td>\n",
       "      <td>0.650537</td>\n",
       "      <td>0.801778</td>\n",
       "      <td>0.686129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824071</td>\n",
       "      <td>0.806327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case303sagittal.jpg</th>\n",
       "      <td>0.766346</td>\n",
       "      <td>0.710590</td>\n",
       "      <td>0.797673</td>\n",
       "      <td>0.856342</td>\n",
       "      <td>0.762811</td>\n",
       "      <td>0.733900</td>\n",
       "      <td>0.844741</td>\n",
       "      <td>0.777999</td>\n",
       "      <td>0.685011</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755234</td>\n",
       "      <td>0.793290</td>\n",
       "      <td>0.720775</td>\n",
       "      <td>0.722805</td>\n",
       "      <td>0.734818</td>\n",
       "      <td>0.872365</td>\n",
       "      <td>0.750331</td>\n",
       "      <td>0.824071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case107coronal.jpg</th>\n",
       "      <td>0.832891</td>\n",
       "      <td>0.908051</td>\n",
       "      <td>0.739138</td>\n",
       "      <td>0.763233</td>\n",
       "      <td>0.866054</td>\n",
       "      <td>0.602104</td>\n",
       "      <td>0.738728</td>\n",
       "      <td>0.668692</td>\n",
       "      <td>0.575349</td>\n",
       "      <td>0.831114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658582</td>\n",
       "      <td>0.717075</td>\n",
       "      <td>0.806627</td>\n",
       "      <td>0.585670</td>\n",
       "      <td>0.612865</td>\n",
       "      <td>0.767610</td>\n",
       "      <td>0.834596</td>\n",
       "      <td>0.806327</td>\n",
       "      <td>0.745475</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows  270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     case325coronal.jpg  case122coronal.jpg  \\\n",
       "Unnamed: 0                                                    \n",
       "case325coronal.jpg             1.000000            0.832942   \n",
       "case122coronal.jpg             0.832942            1.000000   \n",
       "case326sagittal.jpg            0.735341            0.733826   \n",
       "case231sagittal.jpg            0.815261            0.750069   \n",
       "case30coronal.jpg              0.865807            0.852577   \n",
       "...                                 ...                 ...   \n",
       "case277sagittal.jpg            0.782505            0.794565   \n",
       "case197coronal.jpg             0.804853            0.799801   \n",
       "case381sagittal.jpg            0.790026            0.808801   \n",
       "case303sagittal.jpg            0.766346            0.710590   \n",
       "case107coronal.jpg             0.832891            0.908051   \n",
       "\n",
       "                     case326sagittal.jpg  case231sagittal.jpg  \\\n",
       "Unnamed: 0                                                      \n",
       "case325coronal.jpg              0.735341             0.815261   \n",
       "case122coronal.jpg              0.733826             0.750069   \n",
       "case326sagittal.jpg             1.000000             0.799325   \n",
       "case231sagittal.jpg             0.799325             1.000000   \n",
       "case30coronal.jpg               0.700186             0.822330   \n",
       "...                                  ...                  ...   \n",
       "case277sagittal.jpg             0.760559             0.830331   \n",
       "case197coronal.jpg              0.674147             0.778042   \n",
       "case381sagittal.jpg             0.856096             0.823692   \n",
       "case303sagittal.jpg             0.797673             0.856342   \n",
       "case107coronal.jpg              0.739138             0.763233   \n",
       "\n",
       "                     case30coronal.jpg  case297axial.jpg  case219sagittal.jpg  \\\n",
       "Unnamed: 0                                                                      \n",
       "case325coronal.jpg            0.865807          0.638015             0.779249   \n",
       "case122coronal.jpg            0.852577          0.560129             0.721328   \n",
       "case326sagittal.jpg           0.700186          0.638328             0.827238   \n",
       "case231sagittal.jpg           0.822330          0.642854             0.825810   \n",
       "case30coronal.jpg             1.000000          0.527503             0.698878   \n",
       "...                                ...               ...                  ...   \n",
       "case277sagittal.jpg           0.794605          0.663027             0.797273   \n",
       "case197coronal.jpg            0.891447          0.553108             0.667857   \n",
       "case381sagittal.jpg           0.752369          0.660473             0.860385   \n",
       "case303sagittal.jpg           0.762811          0.733900             0.844741   \n",
       "case107coronal.jpg            0.866054          0.602104             0.738728   \n",
       "\n",
       "                     case286axial.jpg  case314axial.jpg  case297coronal.jpg  \\\n",
       "Unnamed: 0                                                                    \n",
       "case325coronal.jpg           0.625735          0.605672            0.870615   \n",
       "case122coronal.jpg           0.651814          0.523295            0.851646   \n",
       "case326sagittal.jpg          0.677034          0.610330            0.741205   \n",
       "case231sagittal.jpg          0.725837          0.592414            0.836343   \n",
       "case30coronal.jpg            0.632859          0.512146            0.869455   \n",
       "...                               ...               ...                 ...   \n",
       "case277sagittal.jpg          0.703301          0.599241            0.795753   \n",
       "case197coronal.jpg           0.628135          0.537501            0.783069   \n",
       "case381sagittal.jpg          0.763673          0.620356            0.801669   \n",
       "case303sagittal.jpg          0.777999          0.685011            0.751449   \n",
       "case107coronal.jpg           0.668692          0.575349            0.831114   \n",
       "\n",
       "                     ...  case13axial.jpg  case300sagittal.jpg  \\\n",
       "Unnamed: 0           ...                                         \n",
       "case325coronal.jpg   ...         0.652710             0.690363   \n",
       "case122coronal.jpg   ...         0.634690             0.693746   \n",
       "case326sagittal.jpg  ...         0.676747             0.720970   \n",
       "case231sagittal.jpg  ...         0.700607             0.740973   \n",
       "case30coronal.jpg    ...         0.598190             0.688923   \n",
       "...                  ...              ...                  ...   \n",
       "case277sagittal.jpg  ...         0.698124             0.801582   \n",
       "case197coronal.jpg   ...         0.612077             0.720362   \n",
       "case381sagittal.jpg  ...         0.730586             0.702392   \n",
       "case303sagittal.jpg  ...         0.755234             0.793290   \n",
       "case107coronal.jpg   ...         0.658582             0.717075   \n",
       "\n",
       "                     case285coronal.jpg  case188axial.jpg  case259axial.jpg  \\\n",
       "Unnamed: 0                                                                    \n",
       "case325coronal.jpg             0.862223          0.623290          0.638169   \n",
       "case122coronal.jpg             0.798509          0.538192          0.558052   \n",
       "case326sagittal.jpg            0.718583          0.626541          0.657490   \n",
       "case231sagittal.jpg            0.843259          0.618296          0.645350   \n",
       "case30coronal.jpg              0.906558          0.511522          0.549753   \n",
       "...                                 ...               ...               ...   \n",
       "case277sagittal.jpg            0.790188          0.648495          0.658357   \n",
       "case197coronal.jpg             0.887545          0.541602          0.582140   \n",
       "case381sagittal.jpg            0.731659          0.644453          0.650537   \n",
       "case303sagittal.jpg            0.720775          0.722805          0.734818   \n",
       "case107coronal.jpg             0.806627          0.585670          0.612865   \n",
       "\n",
       "                     case277sagittal.jpg  case197coronal.jpg  \\\n",
       "Unnamed: 0                                                     \n",
       "case325coronal.jpg              0.782505            0.804853   \n",
       "case122coronal.jpg              0.794565            0.799801   \n",
       "case326sagittal.jpg             0.760559            0.674147   \n",
       "case231sagittal.jpg             0.830331            0.778042   \n",
       "case30coronal.jpg               0.794605            0.891447   \n",
       "...                                  ...                 ...   \n",
       "case277sagittal.jpg             1.000000            0.795315   \n",
       "case197coronal.jpg              0.795315            1.000000   \n",
       "case381sagittal.jpg             0.801778            0.686129   \n",
       "case303sagittal.jpg             0.872365            0.750331   \n",
       "case107coronal.jpg              0.767610            0.834596   \n",
       "\n",
       "                     case381sagittal.jpg  case303sagittal.jpg  \\\n",
       "Unnamed: 0                                                      \n",
       "case325coronal.jpg              0.790026             0.766346   \n",
       "case122coronal.jpg              0.808801             0.710590   \n",
       "case326sagittal.jpg             0.856096             0.797673   \n",
       "case231sagittal.jpg             0.823692             0.856342   \n",
       "case30coronal.jpg               0.752369             0.762811   \n",
       "...                                  ...                  ...   \n",
       "case277sagittal.jpg             0.801778             0.872365   \n",
       "case197coronal.jpg              0.686129             0.750331   \n",
       "case381sagittal.jpg             1.000000             0.824071   \n",
       "case303sagittal.jpg             0.824071             1.000000   \n",
       "case107coronal.jpg              0.806327             0.745475   \n",
       "\n",
       "                     case107coronal.jpg  \n",
       "Unnamed: 0                               \n",
       "case325coronal.jpg             0.832891  \n",
       "case122coronal.jpg             0.908051  \n",
       "case326sagittal.jpg            0.739138  \n",
       "case231sagittal.jpg            0.763233  \n",
       "case30coronal.jpg              0.866054  \n",
       "...                                 ...  \n",
       "case277sagittal.jpg            0.767610  \n",
       "case197coronal.jpg             0.834596  \n",
       "case381sagittal.jpg            0.806327  \n",
       "case303sagittal.jpg            0.745475  \n",
       "case107coronal.jpg             1.000000  \n",
       "\n",
       "[270 rows x 270 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im1.head(270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    " # org\n",
    "org = (50, 50)\n",
    " # fontScale\n",
    "fontScale = 1\n",
    " # White color in BGR\n",
    "color = (255, 255, 255)\n",
    " # Line thickness of 2 px\n",
    "thickness = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./images/selected/case325coronal.jpg')\n",
    "img2 = cv2.imread('./images/selected/case231sagittal.jpg')\n",
    "img3 = cv2.imread('./images/selected/case30coronal.jpg')\n",
    "img4 = cv2.imread('./images/selected/case297axial.jpg')\n",
    "img5 = cv2.imread('./images/selected/case297coronal.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.hconcat([img1, img2, img3, img4, img5])\n",
    "img = cv2.putText(img, f'Caso in analisi case325coronal, similarit con il caso 231sagittal, 30coronal, 297axial, 297coronal', org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "cv2.imwrite(f'../images/similar/case325coronal.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font\n",
    "font = cv2.QT_FONT_NORMAL\n",
    "# org\n",
    "org = (550, 3)\n",
    "# fontScale\n",
    "fontScale = 4\n",
    "# White color in BGR\n",
    "color = (255, 255, 255)\n",
    "# Line thickness of 2 px\n",
    "thickness = 3\n",
    "# Using cv2.putText() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 93/270 [01:22<02:37,  1.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b994d775c676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./images/similar/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./images/similar/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Analisi di similarita'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontScale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./images/similar/{image}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for image in tqdm(os.listdir(\"./images/similar/\")):\n",
    "    img = cv2.imread(os.path.join(\"./images/similar/\", image))\n",
    "    img = cv2.putText(img, f'Analisi di similarita', org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    cv2.imwrite(f'./images/similar/{image}', img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pytorch': conda)",
   "name": "python3810jvsc74a57bd0cb51a0daa07971ff725fa0634097739836b4becdf8968cf417e3b95dc91e2288"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "cb51a0daa07971ff725fa0634097739836b4becdf8968cf417e3b95dc91e2288"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}